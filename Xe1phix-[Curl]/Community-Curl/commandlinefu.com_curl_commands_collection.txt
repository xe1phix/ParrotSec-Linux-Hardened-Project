/////////////////////////////////////////////////////////////////////////////
//
// Linux commands collection part1 ( www.commandlinefu.com )
//
// ---------------------------------------------------
// http://www.commandlinefu.com/commands/browse
//
/////////////////////////////////////////////////////////////////////////////

*
*
*
*
*
*

----------------------------------------

curl ifconfig.me
#Get your external IP address

curl -u user:pass -d status="Tweeting from the shell" http://twitter.com/statuses/update.xml
#Update twitter via curl

curl -u username --silent "https://mail.google.com/mail/feed/atom" | perl -ne 'print "\t" if /<name>/; print "$2\n" if /<(title|name)>(.*)<\/\1>/;'
#Check your unread Gmail from the command line

i="8uyxVmdaJ-w";mplayer -fs $(curl -s "http://www.youtube.com/get_video_info?&video_id=$i" | echo -e $(sed 's/%/\\x/g;s/.*\(v[0-9]\.lscache.*\)/http:\/\/\1/g') | grep -oP '^[^|,]*')
#Stream YouTube URL directly to mplayer.

curl icanhazip.com
#return external ip

cmdfu(){ curl "http://www.commandlinefu.com/commands/matching/$@/$(echo -n $@ | openssl base64)/plaintext"; }
#Search commandlinefu.com from the command line using the API

curl -u username:password --silent "https://mail.google.com/mail/feed/atom" | tr -d '\n' | awk -F '<entry>' '{for (i=2; i<=NF; i++) {print $i}}' | sed -n "s/<title>\(.*\)<\/title.*name>\(.*\)<\/name>.*/\2 - \1/p"
#Check your unread Gmail from the command line

curl ifconfig.me
#What is my public IP-address?

curl -Is slashdot.org | egrep '^X-(F|B|L)' | cut -d \- -f 2
#Gets a random Futurama quote from /.

curl ip.appspot.com
#Get your external IP address

define(){ local y="$@";curl -sA"Opera" "http://www.google.com/search?q=define:${y// /+}"|grep -Po '(?<=<li>)[^<]+'|nl|perl -MHTML::Entities -pe 'decode_entities($_)' 2>/dev/null;}
#Define words and phrases with google.

flight_status() { if [[ $# -eq 3 ]];then offset=$3; else offset=0; fi; curl "http://mobile.flightview.com/TrackByRoute.aspx?view=detail&al="$1"&fn="$2"&dpdat=$(date +%Y%m%d -d ${offset}day)" 2>/dev/null |html2text |grep ":"; }
#track flights from the command line

curl -I www.commandlinefu.com
#Get http headers for an url

ls | curl -F 'sprunge=<-' http://sprunge.us | xclip
#Run a command, store the output in a pastebin on the internet and place the URL on the xclipboard

curl dict://dict.org/d:something
#Look up the definition of a word

curl -s http://checkip.dyndns.org/ | grep -o "[[:digit:].]\+"
#Get your public ip using dyndns

:w !curl -F "sprunge=<-" http://sprunge.us | xclip
#Quickly share code or text from vim to others.

zenity --list --width 500 --height 500 --column 'radio' --column 'url' --print-column 2 $(curl -s http://www.di.fm/ | awk -F '"' '/href="http:.*\.pls.*96k/ {print $2}' | sort | awk -F '/|\.' '{print $(NF-1) " " $0}') | xargs mplayer
#Choose from a nice graphical menu which DI.FM radio station to play

check(){ curl -sI $1 | sed -n 's/Location: *//p';}
#See where a shortened url takes you before click

curl -u username -o bookmarks.xml https://api.del.icio.us/v1/posts/all
#Download all Delicious bookmarks

URL="http://www.google.com";curl -L --w "$URL\nDNS %{time_namelookup}s conn %{time_connect}s time %{time_total}s\nSpeed %{speed_download}bps Size %{size_download}bytes\n" -o/dev/null -s $URL
#How fast is the connexion to a URL, some stats from curl

curl --user login:password -o DeliciousBookmarks.xml -O 'https://api.del.icio.us/v1/posts/all'
#backup delicious bookmarks++

function google { Q="$@"; GOOG_URL='https://www.google.de/search?tbs=li:1&q='; AGENT="Mozilla/4.0"; stream=$(curl -A "$AGENT" -skLm 10 "${GOOG_URL}${Q//\ /+}" | grep -oP '\/url\?q=.+?&amp' | sed 's|/url?q=||; s|&amp||'); echo -e "${stream//\%/\x}"; }
#Google verbatim search on your terminal

curl -s http://checkip.dyndns.org | sed 's/[a-zA-Z<>/ :]//g'
#Another Curl your IP command

for x in `jot - 0 2400 25`; do curl "http://www.commandlinefu.com/commands/browse/sort-by-votes/plaintext/$x" ; done > commandlinefu.txt
#Get all these commands in a text file with description.

id="dMH0bHeiRNg";mplayer -fs http://youtube.com/get_video.php?video_id=$id\&t=$(curl -s http://www.youtube.com/watch?v=$id | sed -n 's/.*, "t": "\([^"]*\)", .*/\1/p')
#Stream YouTube URL directly to mplayer

curl -u twitter-username -d status="Hello World, Twitter!" -d source="cURL" http://twitter.com/statuses/update.xml
#Update twitter via curl (and also set the "from" bit)

curl -n --ssl-reqd --mail-from "<user@gmail.com>" --mail-rcpt "<user@server.tld>" --url smtps://smtp.gmail.com:465 -T file.txt
#Send email with curl and gmail

curl -s 'http://download.finance.yahoo.com/d/quotes.csv?s=csco&f=l1'
#Command Line to Get the Stock Quote via Yahoo

curl -u user -d status="Tweeting from the shell" http://twitter.com/statuses/update.xml
#Update twitter via curl

curl http://www.whatismyip.org/
#What is my ip?

curl -s "http://www.geody.com/geoip.php?ip=$(curl -s icanhazip.com)" | sed '/^IP:/!d;s/<[^>][^>]*>//g'
#geoip information

curl -s "http://feeds.delicious.com/v2/json?count=5" | python -m json.tool | less -R
#JSON processing with Python

curl ifconfig.me
#Get My Public IP Address

imgur(){ $*|convert label:@- png:-|curl -F "image=@-" -F "key=1913b4ac473c692372d108209958fd15" http://api.imgur.com/2/upload.xml|grep -Eo "<original>(.)*</original>" | grep -Eo "http://i.imgur.com/[^<]*";}
#Execute a command, convert output to .png file, upload file to imgur.com, then returning the address of the .png.

curl http://www.commandlinefu.com/commands/by/<your username>/rss|gzip ->commandlinefu-contribs-backup-$(date +%Y-%m-%d-%H.%M.%S).rss.gz
#back up your commandlinefu contributed commands

while [ 1 ]; do curl -s -u username:password http://twitter.com/statuses/friends_timeline.rss|grep title|sed -ne 's/<\/*title>//gp' | head -n 6 |festival --tts; sleep 300;done
#Speak the top 6 lines of your twitter timeline every 5 minutes.....

curl -sd q=Network http://www.commandlinefu.com/search/autocomplete |html2text -width 100
#Search commandlinefu from the CLI

curl http://sohowww.nascom.nasa.gov/data/realtime/eit_195/512/latest.jpg | xli -onroot -fill stdin
#Amazing real time picture of the sun in your wallpaper

echo $(date +%s) > start-time; URL=http://www.google.com; while true; do echo $(curl -L --w %{speed_download} -o/dev/null -s $URL) >> bps; sleep 10; done &
#Log your internet download speed

curl http://www.commandlinefu.com/commands/browse/sort-by-votes/plaintext/[0-2500:25] | grep -v _curl_ > comfu.txt
#Save the Top 2500 commands from commandlinefu to a single text file

d="www.dafont.com/alpha.php?";for c in {a..z}; do l=`curl -s "${d}lettre=${c}"|sed -n 's/.*ge=\([0-9]\{2\}\).*/\1/p'`;for((p=1;p<=l;p++));do for u in `curl -s "${d}page=${p}&lettre=${c}"|egrep -o "http\S*.com/dl/\?f=\w*"`;do aria2c "${u}";done;done;done
#Fetch every font from dafont.com to current folder

dig +short @resolver1.opendns.com myip.opendns.com
#Outgoing IP of server, Faster than the curl/wget-approaches.

curl ifconfig.me/all
#Get your external IP and Network Info

curl -s http://www.census.gov/popclock/data/population/world | python -c 'import json,sys;obj=json.load(sys.stdin);print obj["world"]["population"]'
#Fetch the current human population of Earth

curl -s 'http://checkip.dyndns.org' | sed 's/.*Current IP Address: \([0-9\.]*\).*/\1/g'
#Get your external IP address

urls=('www.ubuntu.com' 'google.com'); for i in ${urls[@]}; do http_code=$(curl -I -s $i -w %{http_code}); echo $i status: ${http_code:9:3}; done
#Check availability of Websites based on HTTP_CODE

curl -I http://localhost
#Send an http HEAD request w/curl

ompload() { curl -# -F file1=@"$1" http://ompldr.org/upload|awk '/Info:|File:|Thumbnail:|BBCode:/{gsub(/<[^<]*?\/?>/,"");$1=$1;print}';}
#Upload images to omploader.org from the command line.

curl http://example.com/a.gz | tar xz
#Extract tarball from internet without local saving

export QQ=$(mktemp -d);(cd $QQ; curl -s -O http://www.commandlinefu.com/commands/browse/sort-by-votes/plaintext/[0-2400:25];for i in $(perl -ne 'print "$1\n" if( /^(\w+\(\))/ )' *|sort -u);do grep -h -m1 -B1 $i *; done)|grep -v '^--' > clf.sh;rm -r $QQ
#grab all commandlinefu shell functions into a single file, suitable for sourcing.

username=matthewbauer; curl -s http://www.commandlinefu.com/commands/by/$username/json | tr '{' '\n' | grep -Eo ',"votes":"[0-9\-]+","' | grep -Eo '[0-9\-]+' | tr '\n' '+' | sed 's/+$/\n/' | bc
#Get your commandlinefu points (upvotes - downvotes)

curl -s ip.appspot.com
#Get your outgoing IP address

step1 ; step2 ; step3 ; step4 ; curl -o- --get 'https://stream.twitter.com/1/statuses/filter.json' --header "$oauth_header" --data "follow=$id"
#Get a stream feed from a Twitter user

Q="YOURSEARCH"; GOOG_URL="http://www.google.com/search?q="; AGENT="Mozilla/4.0"; stream=$(curl -A "$AGENT" -skLm 10 "${GOOG_URL}\"${Q/\ /+}\"" | grep -oP '\/url\?q=.+?&amp' | sed 's/\/url?q=//;s/&amp//'); echo -e "${stream//\%/\x}"
#Search google.com on your terminal

curl -sd 'rid=value&submit=SUBMIT' <URL> > out.html
#Submit data to a HTML form with POST method and save the response

albumart(){ local y="$@";awk '/View larger image/{gsub(/^.*largeImagePopup\(.|., .*$/,"");print;exit}' <(curl -s 'http://www.albumart.org/index.php?srchkey='${y// /+}'&itempage=1&newsearch=1&searchindex=Music');}
#Find the cover image for an album

define(){ local y="$@";curl -sA"Opera" "http://www.google.com/search?q=define:${y// /+}"|grep -Eo '<li>[^<]+'|sed 's/^<li>//g'|nl|/usr/bin/perl -MHTML::Entities -pe 'decode_entities($_)';}
#Define words and phrases with google.

weather(){ curl -s "http://api.wunderground.com/auto/wui/geo/ForecastXML/index.xml?query=${@:-<YOURZIPORLOCATION>}"|perl -ne '/<title>([^<]+)/&&printf "%s: ",$1;/<fcttext>([^<]+)/&&print $1,"\n"';}
#Get the weather forecast for the next 24 to 48 for your location.

qrurl() { curl "http://chart.apis.google.com/chart?chs=150x150&cht=qr&chld=H%7C0&chl=$1" -o qr.$(date +%Y%m%d%H%M%S).png; }
#Create QR codes from a URL.

curl -s "http://www.gravatar.com/avatar/`uuidgen | md5sum | awk '{print $1}'`?s=64&d=identicon&r=PG" | display
#generate random identicon

while true;do n="$(curl -s http://news.yahoo.com/rss/|sed 's/</\n/g'|grep "title>"|sed -e '/^\// d' -e 's/title>/---------- /g' -e '1,3d'|tr '\n' ' ')";for i in $(eval echo {0..${#n}});do echo -ne "\e[s\e[0;0H${n:$i:$COLUMNS}\e[u";sleep .15;done;done &
#Create A Continuous Yahoo! News Ticker For The Terminal

curlftpfs ftp://YourUsername:YourPassword@YourFTPServerURL /tmp/remote-website/ && rsync -av /tmp/remote-website/* /usr/local/data_latest && umount /tmp/remote-website
#backup and synchronize entire remote folder locally (curlftpfs and rsync over FTP using FUSE FS)

watch -n 15 curl -s --connect-timeout 10 http://www.google.com/
#Watch for when your web server returns

curl http://example.com/foo.tar.gz | tar zxvf -
#Extract a remote tarball in the current directory without having to save it locally

curl -s http://bash.org/?random1|grep -oE "<p class=\"quote\">.*</p>.*</p>"|grep -oE "<p class=\"qt.*?</p>"|sed -e 's/<\/p>/\n/g' -e 's/<p class=\"qt\">//g' -e 's/<p class=\"qt\">//g'|perl -ne 'use HTML::Entities;print decode_entities($_),"\n"'|head -1
#Random line from bash.org (funny IRC quotes)

curl -u <user>:<password> -d status="Amarok, now playing: $(dcop amarok default nowPlaying)" http://twitter.com/statuses/update.json
#Twit Amarok "now playing" song

curl -n -d status='Hello from cli' https://twitter.com/statuses/update.xml
#Update twitter from command line without reveal your password

curl -A Mozilla http://www.google.com/search?q=test |html2text -width 80
#Search Google from the command line

curl http://www.phrack.org/archives/tgz/phrack[1-67].tar.gz -o phrack#1.tar.gz
#Download all Phrack .tar.gzs

curl -s checkip.dyndns.org | grep -Eo '[0-9\.]+'
#What is my ip?

tweet () { curl -u UserName -d status="$*" http://twitter.com/statuses/update.xml; }
#another tweet function

curl -s search.twitter.com | awk -F'</?[^>]+>' '/\/intra\/trend\//{print $2}'
#Print trending topics on Twitter

curl -sL xkcd.com | grep '<img [^>]*/><br/>' | sed -r 's|<img src="(.*)" title="(.*)" alt="(.*)" /><br/>|\1\t\2\t\3|' > /tmp/a; curl -s $(cat /tmp/a | cut -f1) | convert - -gravity south -draw "text 0,0 \"$(cat /tmp/a | cut -f2)\"" pdf:- > xkcd.pdf
#Save xkcd to a pdf with captions

curl "http://www.commandlinefu.com/commands/matching/$(echo "$@" | sed 's/ /-/g')/$(echo -n $@ | base64)/plaintext"
#Search commandlinefu.com from the command line using the API

eog `curl -s http://xkcd.com/ | sed -n 's/<h3>Image URL.*: \(.*\)<\/h3>/\1/p'`
#View the newest xkcd comic.

curl -I -H "Accept-Encoding: gzip,deflate" http://example.org
#Check if your webserver supports gzip compression with curl

cmdfu(){ local t=~/cmdfu;echo -e "\n# $1 {{{1">>$t;curl -s "commandlinefu.com/commands/matching/$1/`echo -n $1|base64`/plaintext"|sed '1,2d;s/^#.*/& {{{2/g'>$t;vim -u /dev/null -c "set ft=sh fdm=marker fdl=1 noswf" -M $t;rm $t; }
#Search commandlinefu and view syntax-highlighted results in vim

curl -C - -o partially_downloaded_file 'www.example.com/path/to/the/file'
#resume download using curl

u=`curl -d 'dl.start=Free' $(curl $1|perl -wpi -e 's/^.*"(http:\/\/rs.*)" method.*$/$1/'|egrep '^http'|head -n1)|grep "Level(3) \#2"|perl -wpi -e 's/^.*(http:\/\/rs[^\\\\]*).*$/$1/'`;sleep 60;wget $u
#rapidshare download script in 200 characters

curl -v -k -u user:password "https://members.dyndns.org/nic/update?hostname=<your_domain_name_here>&myip=$(curl -s http://checkip.dyndns.org | sed 's/[a-zA-Z<>/ :]//g')&wildcard=NOCHG&mx=NOCHG&backmx=NOCHG"
#Update dyndns.org with your external IP.

spellcheck(){ typeset y=$@;curl -sd "<spellrequest><text>$y</text></spellrequest>" https://www.google.com/tbproxy/spell|sed -n '/s="[0-9]"/{s/<[^>]*>/ /g;s/\t/ /g;s/ *\(.*\)/Suggestions: \1\n/g;p}'|tee >(grep -Eq '.*'||echo -e "OK");}
#Google Spell Checker

detectlanguage(){ curl -s "http://ajax.googleapis.com/ajax/services/language/detect?v=1.0&q=$@" | sed 's/{"responseData": {"language":"\([^"]*\)".*/\1\n/'; }
#Detect Language of a string

curl -s -d'&url=URL' http://goo.gl/api/url | sed -e 's/{"short_url":"//' -e 's/","added_to_history":false}/\n/'
#Google URL shortener

expandurl() { curl -sIL $1 | grep ^Location; }
#Expand shortened URLs

(cat ~/.bash_history;U='curl -s www.commandlinefu.com';$U/users/signin -c/tmp/.c -d'username=<USER>&password=<PASS>&submit=1'|$U/commands/favourites/json -b/tmp/.c|grep -Po 'nd":.*?[^\\]",'|sed -re 's/.*":"(.*)",/\1/g')>~/.h;HISTFILE=~/.h bash --login
#run shell with your commandlinefu.com's favourites as bash_history

curl -O http://hosted.met-art.com/generated_gallery/full/061606AnnaUkrainePasha/met-art-free-sample-00[00-19].jpg
#bulk dl files based on a pattern

curl -s -u user:password 'http://twitter.com/statuses/friends_timeline.xml?count=5' | xmlstarlet sel -t -m '//status' -v 'user/screen_name' -o ': ' -v 'text' -n
#Get your Tweets from the command line

curl --form username=from_twitter --form password=from_twitter --form media=@/path/to/image --form-string "message=tweet" http://twitpic.com/api/uploadAndPost
#Twitpic upload and Tweet

curl -u USER:PASS -d status="NEW STATUS" http://identi.ca/api/statuses/update.xml
#Updating the status on identi.ca using curl.

curl -s "https://api.github.com/users/${USERNAME}/repos" | ruby -rubygems -e 'require "json"; JSON.load(STDIN.read).each {|repo| %x[git clone #{repo["ssh_url"]} ]}'
#Clone all github repos of a user






